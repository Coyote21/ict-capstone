{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03afdee6",
   "metadata": {},
   "source": [
    "Knowledge Distillation for Question Answering on SQuAD\n",
    "------------------------------------------------------\n",
    "This script demonstrates how to perform knowledge distillation to train a smaller (student) model\n",
    "to mimic the predictions of a larger (teacher) model for the SQuAD question answering task.\n",
    "\n",
    "Key Steps:\n",
    "- Load SQuAD dataset and two models (teacher, student)\n",
    "- Evaluate both models before distillation\n",
    "- Prepare training data with teacher's soft labels (logits)\n",
    "- Define custom Trainer and loss function for distillation (KL-divergence)\n",
    "- Train the student model using knowledge distillation\n",
    "- Evaluate and visualize results before and after distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8177554c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, Trainer, TrainingArguments, TrainerCallback\n",
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "import evaluate\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3684b9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable/disable debugging (smaller dataset for quick runs)\n",
    "debugging = False\n",
    "\n",
    "# Set device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# Tracking variables for loss and metrics\n",
    "loss_values = []           # Stores training loss values per logging step\n",
    "epoch_progress = []        # Stores epoch numbers for plotting loss\n",
    "\n",
    "# Metrics before and after distillation\n",
    "exact_match_before = 0     # Exact Match score before distillation\n",
    "exact_match_after = 0      # Exact Match score after distillation\n",
    "f1_score_before = 0        # F1 score before distillation\n",
    "f1_score_after = 0         # F1 score after distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850f6005",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "1. Load Dataset and Models\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af6acfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SQuAD dataset (train and validation splits)\n",
    "squad = load_dataset(\"squad\")\n",
    "\n",
    "# Load teacher model (large RoBERTa fine-tuned on SQuAD) and its tokenizer\n",
    "teacher_model_name = \"Dingyun-Huang/roberta-large-squad1\" #355M parameters\n",
    "teacher_model = AutoModelForQuestionAnswering.from_pretrained(teacher_model_name)\n",
    "teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_model_name)\n",
    "\n",
    "# Load student model (smaller RoBERTa) and its tokenizer\n",
    "student_model_name = \"deepset/roberta-base-squad2\"  # 124M parameters\n",
    "student_model = AutoModelForQuestionAnswering.from_pretrained(student_model_name)\n",
    "student_tokenizer = AutoTokenizer.from_pretrained(student_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a3fb99",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "2. Evaluation Function\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0089fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, tokenizer, dataset):\n",
    "    \"\"\"\n",
    "    Evaluates a QA model on the given dataset using SQuAD metrics (Exact Match, F1).\n",
    "\n",
    "    Args:\n",
    "        model: HuggingFace QA model (teacher or student)\n",
    "        tokenizer: Corresponding tokenizer\n",
    "        dataset: Dataset split to evaluate (e.g., squad[\"validation\"])\n",
    "\n",
    "    Returns:\n",
    "        dict: {'exact_match': float, 'f1': float}\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    \n",
    "    metric = evaluate.load(\"squad\")\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for example in tqdm(dataset, desc=\"Evaluating\"):\n",
    "        # Tokenize inputs\n",
    "        inputs = tokenizer(\n",
    "            example[\"context\"], example[\"question\"], truncation=True, padding=True, return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Move inputs to the same device as the model\n",
    "        inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "        \n",
    "        # Get model outputs\n",
    "        outputs = model(**inputs)\n",
    "        start_logits, end_logits = outputs.start_logits, outputs.end_logits\n",
    "        start_idx = torch.argmax(start_logits, dim=-1).item()\n",
    "        end_idx = torch.argmax(end_logits, dim=-1).item()\n",
    "        \n",
    "        # Decode prediction\n",
    "        prediction = tokenizer.decode(inputs[\"input_ids\"][0][start_idx:end_idx + 1])\n",
    "        \n",
    "        # Append to predictions\n",
    "        predictions.append({\n",
    "            \"id\": example[\"id\"],\n",
    "            \"prediction_text\": prediction\n",
    "        })\n",
    "\n",
    "        # Append to references (ground truth)\n",
    "        references.append({\n",
    "            \"id\": example[\"id\"],\n",
    "            \"answers\": example[\"answers\"]\n",
    "        })\n",
    "\n",
    "    # Compute metrics\n",
    "    result = metric.compute(predictions=predictions, references=references)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6720ac8a",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "3. Preprocessing Functions\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f213f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare validation data for evaluation\n",
    "def preprocess_validation_data(example):\n",
    "    \"\"\"\n",
    "    Tokenizes validation data for the student model.\n",
    "\n",
    "    Args:\n",
    "        example: A single SQuAD example\n",
    "\n",
    "    Returns:\n",
    "        dict: Tokenized inputs\n",
    "    \"\"\"\n",
    "    # Tokenize context and question\n",
    "    inputs = student_tokenizer(\n",
    "        example[\"context\"],\n",
    "        example[\"question\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=384,\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e88411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training data for distillation\n",
    "def preprocess_data(example):\n",
    "    \"\"\"\n",
    "    Prepares training data for distillation by attaching teacher's logits.\n",
    "\n",
    "    Args:\n",
    "        example: A single SQuAD example\n",
    "\n",
    "    Returns:\n",
    "        dict: Example with input_ids, attention_mask, and teacher's start/end logits\n",
    "    \"\"\"\n",
    "    # Move teacher model to appropriate device\n",
    "    teacher_model.to(device)\n",
    "    \n",
    "    # Tokenize context and question\n",
    "    inputs = teacher_tokenizer(\n",
    "        example[\"context\"], \n",
    "        example[\"question\"], \n",
    "        truncation=True, \n",
    "        padding=\"max_length\", \n",
    "        max_length=384,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Move inputs to the same device as the teacher model\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    \n",
    "    # Get logits from the teacher model\n",
    "    with torch.no_grad():\n",
    "        outputs = teacher_model(**inputs)\n",
    "    \n",
    "    # Add teacher logits to the example\n",
    "    example[\"input_ids\"] = inputs[\"input_ids\"][0].cpu().tolist()\n",
    "    example[\"attention_mask\"] = inputs[\"attention_mask\"][0].cpu().tolist()\n",
    "    example[\"start_logits\"] = outputs.start_logits[0].cpu().tolist()\n",
    "    example[\"end_logits\"] = outputs.end_logits[0].cpu().tolist()\n",
    "    \n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc78863b",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "4. Evaluate Teacher and Student Before Distillation\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24431845",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = squad[\"validation\"]\n",
    "\n",
    "# Evaluate teacher model\n",
    "print(\"Teacher Model Evaluation\")\n",
    "result = evaluate_model(teacher_model, teacher_tokenizer, validation_dataset)\n",
    "print(f\"Exact Match: {result['exact_match']:.2f}%\")\n",
    "print(f\"F1 Score: {result['f1']:.2f}%\\n\")\n",
    "\n",
    "# Evaluate student model on validation set (before distillation)\n",
    "print(\"Student Model Evaluation (Before Distillation)\")\n",
    "result = evaluate_model(student_model, student_tokenizer, validation_dataset)\n",
    "print(f\"Exact Match: {result['exact_match']:.2f}%\")\n",
    "print(f\"F1 Score: {result['f1']:.2f}%\\n\")\n",
    "\n",
    "# Save the results for use in Graphs\n",
    "exact_match_before = result['exact_match']\n",
    "f1_score_before = result['f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d16d43",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "5. Prepare Training and Validation Data\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1c70dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging, use a subset of training data for faster runs\n",
    "# Apply preprocessing to training dataset\n",
    "if debugging: \n",
    "    train_dataset = squad[\"train\"].select(range(10000)).map(preprocess_data)\n",
    "else:\n",
    "    train_dataset = squad[\"train\"].map(preprocess_data)    \n",
    "\n",
    "# Apply preprocessing to validation dataset\n",
    "validation_set = validation_dataset.map(preprocess_validation_data, batched=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c385181",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "6. Training Arguments\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd51408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments for student model\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./trained_student\",\n",
    "    logging_steps=10,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=12,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    "    remove_unused_columns=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bc93e5",
   "metadata": {},
   "source": [
    "# -------------------------------\n",
    "# 7. Custom Callback for Logging\n",
    "# -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e615d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TeacherTrainingProgress(TrainerCallback):\n",
    "    \"\"\"\n",
    "    Custom callback to log loss and epoch progress during training.\n",
    "    \"\"\"\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and 'loss' in logs:\n",
    "            loss_values.append(logs['loss'])\n",
    "            epoch_progress.append(logs['epoch'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b057f",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "8. Custom Trainer for Distillation\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e7dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DistillationTrainer(Trainer):    \n",
    "    \"\"\"\n",
    "    Custom Trainer that computes the distillation loss (KL divergence) between\n",
    "    teacher's and student's predicted logits.\n",
    "    \"\"\"\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "        \n",
    "        # Compute KL Divergence loss between teacher and student logits\n",
    "        start_loss = torch.nn.functional.kl_div(\n",
    "            torch.nn.functional.log_softmax(outputs.start_logits, dim=-1),\n",
    "            torch.nn.functional.softmax(inputs[\"start_logits\"], dim=-1),\n",
    "            reduction=\"batchmean\"\n",
    "        )\n",
    "        end_loss = torch.nn.functional.kl_div(\n",
    "            torch.nn.functional.log_softmax(outputs.end_logits, dim=-1),\n",
    "            torch.nn.functional.softmax(inputs[\"end_logits\"], dim=-1),\n",
    "            reduction=\"batchmean\"\n",
    "        )\n",
    "        \n",
    "        # Average the start and end losses\n",
    "        loss = (start_loss + end_loss) / 2\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fecb95",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "9. Custom Data Collator\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7cf012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FullyCustomDataCollator:\n",
    "    \"\"\"\n",
    "    Custom data collator to pad inputs and attach teacher logits for each batch.\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features):\n",
    "        # Filter out non-tokenized fields before padding\n",
    "        tokenized_features = [\n",
    "            {k: v for k, v in f.items() if k in [\"input_ids\", \"attention_mask\", \"token_type_ids\"]}\n",
    "            for f in features\n",
    "        ]\n",
    "\n",
    "        # Dynamically pad input_ids and attention_mask using the tokenizer\n",
    "        batch = self.tokenizer.pad(\n",
    "            tokenized_features,\n",
    "            padding=True,\n",
    "            max_length=None,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        # Add custom fields (e.g., start_logits and end_logits) to the batch\n",
    "        if \"start_logits\" in features[0]:\n",
    "            batch[\"start_logits\"] = torch.tensor([f[\"start_logits\"] for f in features], dtype=torch.float32)\n",
    "        if \"end_logits\" in features[0]:\n",
    "            batch[\"end_logits\"] = torch.tensor([f[\"end_logits\"] for f in features], dtype=torch.float32)\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3990b986",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = FullyCustomDataCollator(tokenizer=student_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fe0645",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "10. Train Student Model with Distillation\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fa6974",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = DistillationTrainer(\n",
    "    model=student_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=validation_set,\n",
    "    data_collator=data_collator,\n",
    "    callbacks=[TeacherTrainingProgress()]\n",
    ")\n",
    "\n",
    "train_result = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335df865",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "11. Evaluate Student After Distillation\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e0a42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Student Model Evaluation after Distillation\")\n",
    "result = evaluate_model(student_model, student_tokenizer, validation_dataset)\n",
    "print(f\"Exact Match: {result['exact_match']:.2f}%\")\n",
    "print(f\"F1 Score: {result['f1']:.2f}%\\n\")\n",
    "\n",
    "# Save the results for use in Graphs\n",
    "exact_match_after = result['exact_match']\n",
    "f1_score_after = result['f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfe698c",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "12. Visualization\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a03dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss values per epoch\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epoch_progress, loss_values, label=\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Per Epoch\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2615892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot: Exact Match before vs after distillation\n",
    "plt.figure(figsize=(8, 6))\n",
    "labels = [\"Before Distillation\", \"After Distillation\"]\n",
    "exact_match_scores = [exact_match_before, exact_match_after]\n",
    "plt.bar(labels, exact_match_scores, color=['blue', 'green'])\n",
    "plt.ylabel(\"Exact Match (%)\")\n",
    "plt.title(\"Exact Match Score Before and After Distillation\")\n",
    "for i, v in enumerate(exact_match_scores):\n",
    "    plt.text(i, v + 1, f\"{v:.1f}%\", ha='center', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fea1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot: F1 score before vs after distillation\n",
    "plt.figure(figsize=(8, 6))\n",
    "f1_scores = [f1_score_before, f1_score_after]\n",
    "plt.bar(labels, f1_scores, color=['orange', 'red'])\n",
    "plt.ylabel(\"F1 Score (%)\")\n",
    "plt.title(\"F1 Score Before and After Distillation\")\n",
    "for i, v in enumerate(f1_scores):\n",
    "    plt.text(i, v + 1, f\"{v:.1f}%\", ha='center', fontsize=12)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94687d0f",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "13. Save the Distilled Model\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db7e47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.save_pretrained(\"./distilled_model\")\n",
    "student_tokenizer.save_pretrained(\"./distilled_model\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
